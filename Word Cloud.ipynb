{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from subprocess import check_output\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import nltk.corpus # for stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "wordcloud_stopwords = set(STOPWORDS)\n",
    "print(nltk_stopwords - wordcloud_stopwords)\n",
    "print(wordcloud_stopwords - nltk_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Log.txt') as f:\n",
    "    data = ''\n",
    "    \n",
    "    for line in f:\n",
    "        data += line\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = wordpunct_tokenize(data)\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_filtered = []\n",
    "nltk_filtered = []\n",
    "\n",
    "for word in tokenized:\n",
    "    if word not in wordcloud_stopwords:\n",
    "        wordcloud_filtered.append(word)\n",
    "        \n",
    "    if word not in nltk_filtered:\n",
    "        nltk_filtered.append(word)\n",
    "\n",
    "print('Words in nltk set that are not in wordcloud set:', set(nltk_filtered) - set(wordcloud_filtered))\n",
    "print('Words in wordcloud set that are not in nltk set:', set(wordcloud_filtered) - set(nltk_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the wordcloud stopwords gets rid of more uninteresting words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "stopwords.add('page')\n",
    "stopwords.add('paper')\n",
    "stopwords.add('readings')\n",
    "stopwords.add('research')\n",
    "stopwords.add('summary')\n",
    "\n",
    "stopwords.add('look')\n",
    "stopwords.add('possible')\n",
    "stopwords.add('related')\n",
    "stopwords.add('seemed')\n",
    "stopwords.add('seems')\n",
    "stopwords.add('understand')\n",
    "stopwords.add('use')\n",
    "stopwords.add('used')\n",
    "stopwords.add('using')\n",
    "\n",
    "stopwords.add('wikipedia')\n",
    "\n",
    "stopwords.add('________________')\n",
    "# time related words\n",
    "stopwords.add('date')\n",
    "stopwords.add('november')\n",
    "stopwords.add('week')\n",
    "stopwords.add('monday')\n",
    "stopwords.add('tuesday')\n",
    "stopwords.add('wednesday')\n",
    "stopwords.add('thursday')\n",
    "stopwords.add('friday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stemmed = []\n",
    "\n",
    "for word in wordcloud_filtered:\n",
    "    stemmed.append(stemmer.stem(word))\n",
    "    \n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n' \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = []\n",
    "\n",
    "for word in wordcloud_filtered:\n",
    "    _, pos = nltk.pos_tag([word])[0]\n",
    "    pos = penn2morphy(pos)\n",
    "    lemmatized.append(lemmatizer.lemmatize(word, pos=pos))\n",
    "    print(word, '->', pos, lemmatized[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(stopwords=stopwords, \n",
    "                      width=1920,\n",
    "                      height=1080, \n",
    "                      background_color='white',\n",
    "                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_wordcloud = wordcloud.generate(data)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(regular_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming_wordcloud = wordcloud.generate(' '.join(stemmed))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(stemming_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizing_wordcloud = wordcloud.generate(' '.join(lemmatized))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(lemmatizing_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave('log_wordcloud.png', regular_wordcloud, format=\"png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
